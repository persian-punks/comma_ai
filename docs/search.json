[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "",
    "text": "Comma.ai is one of the few respectable tech companies offering one of the most advanced self-driving products: the comma 3x. - Automates ~70+% of daily driving. - Performs exceptionally well on highways and other roads with identifiable lanes. - Installed and mounted on a car’s front windshield, so it can receive a live data feed of the road. - Using this live feed, the comma 3x projects the path for the vehicle to follow.\n\n\n      Comma uploads driving data to its servers to train better models and improve the self-driving experience over time. We can access our driving data using the comma API. Using our driving data, we can create metrics to analyze our driving patterns and behavior.\n\n\n\nVisit the website for a more comprehensive overview: comma.ai"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "",
    "text": "Comma.ai is one of the few respectable tech companies offering one of the most advanced self-driving products: the comma 3x. - Automates ~70+% of daily driving. - Performs exceptionally well on highways and other roads with identifiable lanes. - Installed and mounted on a car’s front windshield, so it can receive a live data feed of the road. - Using this live feed, the comma 3x projects the path for the vehicle to follow.\n\n\n      Comma uploads driving data to its servers to train better models and improve the self-driving experience over time. We can access our driving data using the comma API. Using our driving data, we can create metrics to analyze our driving patterns and behavior.\n\n\n\nVisit the website for a more comprehensive overview: comma.ai"
  },
  {
    "objectID": "index.html#set-up-virtual-environmentinstall-dependencies-mac",
    "href": "index.html#set-up-virtual-environmentinstall-dependencies-mac",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Set Up Virtual Environment/Install Dependencies (Mac)",
    "text": "Set Up Virtual Environment/Install Dependencies (Mac)\n\nExecute these commands in your terminal\n\nCreate local virtual env: python3 -m venv .venv\nActivate local virtual env: source .venv/bin/activate\nInstall Python dependencies: pip3 install -r requirements.txt\nInstall Homebrew: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nInstall ‘ffmpeg’ via Homebrew: brew install ffmpeg\nOPTIONAL - Connect your personal Comma AI device:\n\ntouch .env\nnano .env - opens .env file in terminal\nCOMMA_AI_KEY=\"insert your Comma API key\"\nDONGLE_ID=\"insert your dongle ID\"\nSave file and exit nano"
  },
  {
    "objectID": "index.html#import-libraries-set-configurations",
    "href": "index.html#import-libraries-set-configurations",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Import Libraries & Set Configurations",
    "text": "Import Libraries & Set Configurations\n\nimport pandas as pd # data processing\nimport urllib.request # download file from URL\nimport ssl # bypass SSL certificate\nimport warnings # ignore non-critical warning outputs\nimport cv2 # video processing\nimport matplotlib.pyplot as plt # data visualization\nimport matplotlib.image as mpimg # data visualization\nimport subprocess # running terminal commands in Python script\nimport seaborn_image as isns # data visualization\nfrom requests import get # API request\nfrom time import sleep # Prevent triggering the API limit\nfrom os import environ, listdir, mkdir, makedirs # directory manipulation & file saving\nimport os.path\nfrom dotenv import load_dotenv # load environment variables\nfrom tqdm import tqdm # added as a meme, prints unnecessary loading bar in terminal during for loops\nfrom moviepy.editor import VideoFileClip, concatenate_videoclips # video editing\nplt.style.use('ggplot')\nwarnings.filterwarnings('ignore')\nssl._create_default_https_context = ssl._create_unverified_context\npd.set_option('display.max_columns', None)\nload_dotenv()\n\nTrue"
  },
  {
    "objectID": "index.html#create-variables-for-api-requests",
    "href": "index.html#create-variables-for-api-requests",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Create Variables for API Requests",
    "text": "Create Variables for API Requests\nThe first step to receive the recording of my longest trip (College Station) since installation is making sure I send the correct parameters to the API endpoint. Comma.ai’s API requests require an authentication token and the dongle ID of a user’s Comma device.\n\nTOKEN= environ.get('COMMA_AI_KEY')\nDONGLE_ID = environ.get('DONGLE_ID')\nheaders = {\n    'Authorization': 'JWT {}'.format(TOKEN)\n}\nBASE_URL = 'https://api.commadotai.com'"
  },
  {
    "objectID": "index.html#createcheck-file-paths-exist",
    "href": "index.html#createcheck-file-paths-exist",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Create/Check File Paths Exist",
    "text": "Create/Check File Paths Exist\n\nroute_data_path = 'data/route-data'\nvid_urls_path = 'data/vid-urls'\nvid_save_files_path = 'data/vid-files'\nmp4_directory = 'data/vid-mp4'\nfull_vid_path = 'data/vid-full'\nimages_path = 'data/route-images'\n\npaths = [\n    route_data_path,\n    vid_urls_path,\n    vid_save_files_path,\n    mp4_directory,\n    full_vid_path,\n    images_path,\n]\n\nfor route_vid_path in paths:\n    if os.path.exists(route_vid_path) == False: mkdir(route_vid_path)\n    else: print(route_vid_path)\n\ndata/route-data\ndata/vid-urls\ndata/vid-files\ndata/vid-mp4\ndata/vid-full\ndata/route-images"
  },
  {
    "objectID": "index.html#api-request-1---returns-user-driving-data",
    "href": "index.html#api-request-1---returns-user-driving-data",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "API Request #1 - Returns User Driving Data",
    "text": "API Request #1 - Returns User Driving Data\nAfter creating the API variables, we can request the API endpoint which returns our driving data in the response output. The first API request will return various metrics from all of my driving trips since installing my Comma 3x. It will provide us with the route name for every trip. For our current task, we have chosen our longest trip by miles, so we will sort the dataset by longest trip to identify the route name. After sorting by descending order, the first row’s value in column fullname is the route name.\n\ndef query_route_data(BASE_URL: str):\n    # Send API request\n    resp = get(\n        f'{BASE_URL}/v1/devices/{DONGLE_ID}/routes_segments?start=1706050612200&end=1798696800000', headers=headers, \n        verify=False)\n\n    # Convert API response to JSON\n    content = resp.json()\n\n    # Create DataFrame w/ API Response\n    df = pd.DataFrame(content)\n\n    # Remove latitude, longitude variables for privacy.\n    df = df[[\n        'fullname', 'length', 'create_time', 'end_time_utc_millis',\n        'end_time', 'init_logmonotime', 'maxqcamera', 'maxqlog', \n        'platform', 'procqcamera', 'procqlog', 'segment_end_times', \n        'segment_numbers', 'segment_start_times', 'start_time_utc_millis', 'version'\n    ]]\n\n    # Time metric conversions\n    df['time_diff_millis'] = df['end_time_utc_millis'] - df['start_time_utc_millis']\n    df['time_diff_seconds'] = df['time_diff_millis'].__truediv__(1000)\n    df['time_diff_minutes'] = df['time_diff_seconds'].__truediv__(60)\n    df['time_diff_hours'] = df['time_diff_minutes'].__truediv__(60)\n    df['end_time'] = pd.to_datetime(df['end_time']).dt.strftime(\"%Y-%m-%d\")\n\n    # strip_dongle_id\n    removed_dongle_route_list = []\n    for idx, row in df.iterrows():\n        stripped_value = row['fullname'].replace(f'{DONGLE_ID}', 'INSERT-DONGLE-ID-HERE')\n        removed_dongle_route_list.append(stripped_value)\n    df['fullname'] = removed_dongle_route_list\n    \n    df = df.sort_values('end_time', ascending=True)\n    # df = df.sort_values('length', ascending=False)\n    route_names = df['fullname'].tolist()\n    route_df = pd.DataFrame()\n    route_df['route_name'] = route_names\n\n    # Save route data to csv\n    route_df.to_csv(f'{route_data_path}/route_names.csv', index=False)\n    df.to_csv(f'{route_data_path}/trip_driving_data.csv', index=False)\n    print(df.head(5))\n\nquery_route_data(BASE_URL=BASE_URL)\n\n                                        fullname   length  create_time  \\\n1137  INSERT-DONGLE-ID-HERE|2024-05-18--11-46-31  13.3981   1716053567   \n1136  INSERT-DONGLE-ID-HERE|2024-05-18--12-16-32  12.8193   1716053709   \n1135  INSERT-DONGLE-ID-HERE|2024-05-18--13-49-14  15.5973   1716142755   \n1132  INSERT-DONGLE-ID-HERE|2024-05-19--16-07-36  14.0763   1716152927   \n1134  INSERT-DONGLE-ID-HERE|2024-05-19--12-57-25  15.0813   1716143074   \n\n      end_time_utc_millis    end_time  init_logmonotime  maxqcamera  maxqlog  \\\n1137        1716051869000  2024-05-18       72515753305          17       17   \n1136        1716053832000  2024-05-18     1874210939511          20       20   \n1135        1716060651000  2024-05-18     7436056976713          41       41   \n1132        1716153719000  2024-05-19    11507666633758          14       14   \n1134        1716143207000  2024-05-19       97798164701          29       29   \n\n               platform  procqcamera  procqlog  \\\n1137  TOYOTA CAMRY 2021           17        17   \n1136  TOYOTA CAMRY 2021           20        20   \n1135  TOYOTA CAMRY 2021           41        41   \n1132  TOYOTA CAMRY 2021           14        14   \n1134  TOYOTA CAMRY 2021           29        29   \n\n                                      segment_end_times  \\\n1137  [1716050851000, 1716050911000, 1716050971000, ...   \n1136  [1716052652000, 1716052712000, 1716052772000, ...   \n1135  [1716058214000, 1716058274000, 1716058334000, ...   \n1132  [1716152915000, 1716152975000, 1716153035000, ...   \n1134  [1716141506000, 1716141566000, 1716141626000, ...   \n\n                                        segment_numbers  \\\n1137  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n1136  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n1135  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n1132  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n1134  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n\n                                    segment_start_times  \\\n1137  [1716050791000, 1716050851000, 1716050911000, ...   \n1136  [1716052592000, 1716052652000, 1716052712000, ...   \n1135  [1716058154000, 1716058214000, 1716058274000, ...   \n1132  [1716152855000, 1716152915000, 1716152975000, ...   \n1134  [1716141446000, 1716141506000, 1716141566000, ...   \n\n      start_time_utc_millis        version  time_diff_millis  \\\n1137          1716050791000  0.9.6-release           1078000   \n1136          1716052592000  0.9.6-release           1240000   \n1135          1716058154000  0.9.6-release           2497000   \n1132          1716152855000  0.9.6-release            864000   \n1134          1716141446000  0.9.6-release           1761000   \n\n      time_diff_seconds  time_diff_minutes  time_diff_hours  \n1137             1078.0          17.966667         0.299444  \n1136             1240.0          20.666667         0.344444  \n1135             2497.0          41.616667         0.693611  \n1132              864.0          14.400000         0.240000  \n1134             1761.0          29.350000         0.489167"
  },
  {
    "objectID": "index.html#api-request-2---returns-urls-to-download-video-files",
    "href": "index.html#api-request-2---returns-urls-to-download-video-files",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "API Request #2 - Returns URLs To Download Video Files",
    "text": "API Request #2 - Returns URLs To Download Video Files\nUsing the route name, we can submit our second API request to an endpoint storing the URLs of our downloadable video files (.ts file type). Before downloading our files, we store the URLs from the API response in a text file, so we can access the URL data locally.\n\ndef query_to_extract_urls(BASE_URL: str, route_name: str):\n    df = pd.read_csv(f'{route_data_path}/route_names.csv')\n\n    # Insert dongle ID into route name\n    route_name_dongle_list = []\n    for idx, row in df.iterrows():\n        converted_route_name = row['route_name'].replace(\n            'INSERT-DONGLE-ID-HERE', f'{DONGLE_ID}')\n        route_name_dongle_list.append(converted_route_name)\n    df['route_name'] = route_name_dongle_list\n\n    download_recent_trip_vids = df.loc[df['route_name'] == route_name]\n    download_recent_trip_vids = download_recent_trip_vids['route_name'].tolist()\n\n    for route in tqdm(download_recent_trip_vids):\n        with get(\n            f'{BASE_URL}/v1/route/{route}/files', \n            headers=headers, verify=False, \n            stream=True, \n            timeout=10) as response:\n            content = response.json()['qcameras']\n            # print(content)\n            with open(\n                f'{vid_urls_path}' + f'/{route.replace(f\"{DONGLE_ID}\", \"\").replace(\"|\", \"\").replace(\"-\",\"\")}.txt',\n                mode=\"wb\") as file:\n                for url in content:\n                    file.write(\n                        url.replace(\n                            f\"{DONGLE_ID}\", \n                            \"INSERT-DONGLE-ID-HERE\").encode('utf-8') + ' \\n'.encode('utf-8'))\n        urls_list = []\n        with open(\n            f'{vid_urls_path}/{route_name.replace(f\"{DONGLE_ID}\", \"\").replace(\"|\", \"\").replace(\"-\",\"\")}.txt',\n            mode=\"r\") as file:\n            url_list = file.readlines()\n            for url in url_list:\n                new_url = url.replace('INSERT-DONGLE-ID-HERE', f'{DONGLE_ID}')\n                # response = get(url)\n                urls_list.append(url)\n            # print(urls_list)\n\n        parsed_route = f'{vid_save_files_path}/{route_name.replace(f\"{DONGLE_ID}\", \"\").replace(\"|\", \"\").replace(\"-\",\"\")}'\n        if os.path.exists(parsed_route): pass\n        else: mkdir(parsed_route)\n        print(\"Total number of URLs to download:\", len(urls_list))\n        print(\"\\n Preview 5 URLs:\", *url_list[:5], sep='\\n')\n\nquery_to_extract_urls(BASE_URL=BASE_URL, route_name=f'{DONGLE_ID}|00000113--deccd0eef8')\n\nTotal number of URLs to download: 93\n\n Preview 5 URLs:\nhttps://commadata2.blob.core.windows.net/qlog/INSERT-DONGLE-ID-HERE/00000113--deccd0eef8/0/qcamera.ts?se=2025-05-18T16%3A45%3A08Z&sp=r&sv=2024-08-04&sr=b&rscd=attachment%3B%20filename%3DINSERT-DONGLE-ID-HERE_00000113--deccd0eef8--0--qcamera.ts&sig=XmFrzDnfzorZJ79UJwMMFJxYtOuFj4Dh/vc36ItigL8%3D \n\nhttps://commadata2.blob.core.windows.net/qlog/INSERT-DONGLE-ID-HERE/00000113--deccd0eef8/1/qcamera.ts?se=2025-05-18T16%3A45%3A08Z&sp=r&sv=2024-08-04&sr=b&rscd=attachment%3B%20filename%3DINSERT-DONGLE-ID-HERE_00000113--deccd0eef8--1--qcamera.ts&sig=p3Aj81kOsbRoSrHzU7v1GvIl9u9LOmTmm%2Bff%2BdKuuC8%3D \n\nhttps://commadata2.blob.core.windows.net/qlog/INSERT-DONGLE-ID-HERE/00000113--deccd0eef8/2/qcamera.ts?se=2025-05-18T16%3A45%3A08Z&sp=r&sv=2024-08-04&sr=b&rscd=attachment%3B%20filename%3DINSERT-DONGLE-ID-HERE_00000113--deccd0eef8--2--qcamera.ts&sig=Vzq/wPTIrcf%2BCRMNDtWh/C0aGsQL/yTwYT5KWz0y7iw%3D \n\nhttps://commadata2.blob.core.windows.net/qlog/INSERT-DONGLE-ID-HERE/00000113--deccd0eef8/3/qcamera.ts?se=2025-05-18T16%3A45%3A08Z&sp=r&sv=2024-08-04&sr=b&rscd=attachment%3B%20filename%3DINSERT-DONGLE-ID-HERE_00000113--deccd0eef8--3--qcamera.ts&sig=qjwGeZn%2BYzjCiT3L18Jn6W/0MpSI/hEymQOegIJcRDA%3D \n\nhttps://commadata2.blob.core.windows.net/qlog/INSERT-DONGLE-ID-HERE/00000113--deccd0eef8/4/qcamera.ts?se=2025-05-18T16%3A45%3A08Z&sp=r&sv=2024-08-04&sr=b&rscd=attachment%3B%20filename%3DINSERT-DONGLE-ID-HERE_00000113--deccd0eef8--4--qcamera.ts&sig=3b5Pbs5uhiuNRtB2M0923WgYuBAzrIX5chqBfX0iWvQ%3D"
  },
  {
    "objectID": "index.html#downloading-our-driving-video-.ts-files",
    "href": "index.html#downloading-our-driving-video-.ts-files",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Downloading Our Driving Video .ts Files",
    "text": "Downloading Our Driving Video .ts Files\nWith our URLs stored locally in a text file, we can iterate over and request each URL to download and save our video files locally.  Note: You cannot run this function since I did not provide my API token or dongle id\n\ndef download_vid_files_from_url(route_name: str):\n    for filename in tqdm(listdir(vid_urls_path)):\n        print(\"Video URLs file:\", vid_urls_path +  f'/{filename}')\n        count = 0\n        f = os.path.join(vid_urls_path, filename)\n        file = open(f, 'rb')\n        print(\"Beginning video downloads...\")\n        for url in tqdm(file):\n            decode_url = url.decode('utf-8')\n            url_insert_dongle_id = decode_url.replace(\n                \"INSERT-DONGLE-ID-HERE\", f\"{DONGLE_ID}\")\n            create_route_vid_path = route_name.replace('.txt', '').replace(f'{DONGLE_ID}', '').replace('|',\"\").replace(\"-\",\"\")\n            urllib.request.urlretrieve(\n                url_insert_dongle_id, \n                vid_save_files_path +\n                f'/{create_route_vid_path}' + \n                f'/x{str(count).rjust(3, \"0\")}_' + \n                f'{route_name.replace(\".txt\", \"\").replace(f\"{DONGLE_ID}\",\"\").replace(\"|\",\"\").replace(\"-\",\"\")}.ts')\n            count += 1\n        sleep(17)\n        print(\"Video files successfully downloaded!\")\n        print(\"Total files downloaded:\", count)\n        \ndownload_vid_files_from_url(route_name=f'{DONGLE_ID}|00000113--deccd0eef8')\n\nVideo URLs file: data/vid-urls/00000113deccd0eef8.txt\nBeginning video downloads...\nVideo files successfully downloaded!\nTotal files downloaded: 93"
  },
  {
    "objectID": "index.html#converting-file-type-to-mp4",
    "href": "index.html#converting-file-type-to-mp4",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Converting File Type to MP4",
    "text": "Converting File Type to MP4\nAfter looping over the URLs to download our driving videos, we convert our video file type from .ts to .mp4 since it’s one of the most common file types for videos. We store the converted videos in a separate directory, so that we can loop over the 147 files without the original files making trouble.\n\ndef convert_ts_to_mp4(vid_clip_directory: str):\n    route_directory = vid_save_files_path + vid_clip_directory\n    if os.path.exists(mp4_directory + vid_clip_directory) == False: \n        mkdir(mp4_directory + vid_clip_directory)\n    else: pass\n    \n    files_list = []\n    for file in listdir(route_directory): files_list.append(file)\n    files_list.sort()\n    for filename in files_list:\n        infile = route_directory + f'/{filename}'\n        outfile = mp4_directory + f'/{vid_clip_directory}' + f'/{filename.replace(\".ts\", \"\")}.mp4'\n        subprocess.run([\n            'ffmpeg',\n            '-i',\n            infile,\n            outfile,\n        ])\n# convert_ts_to_mp4(vid_clip_directory='/00000113deccd0eef8')"
  },
  {
    "objectID": "index.html#concatenate-the-video-clips",
    "href": "index.html#concatenate-the-video-clips",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Concatenate The Video Clips",
    "text": "Concatenate The Video Clips\nTo facilitate the distribution of video data, Comma API splits our video data into short clips to reduce the memory size. Our objective is to capture images from our entire trip; therefore, we need to concatenate the 147 video files. Ideally, we’d prefer to create one MP4 from the concatenation. Due to storage size, we split the final trip into 4 parts. If we don’t split the video data in this manner, the file size would be too large and we wouldn’t be able to push the video to GitHub.\n\ndef concat_vid_clips(vid_clip_directory: str):\n    vid_clips_list = []\n    route_mp4_path = mp4_directory + vid_clip_directory\n\n    files_list = []\n    for file in listdir(route_mp4_path): files_list.append(file)\n    files_list.sort()\n\n    def multi_part_full_vid(video_title: str, start_range: int, end_range: int):\n        for filename in files_list[start_range:end_range]:\n            f = os.path.join(route_mp4_path, filename)\n            vid_clip = VideoFileClip(f)\n            vid_clips_list.append(vid_clip)\n        final_clip = concatenate_videoclips(clips=vid_clips_list, method='chain')\n        final_clip.write_videofile(f'{full_vid_path}' + f'/{video_title}.mp4')\n        vid_clips_list.clear()\n\n    multi_part_full_vid(video_title=\"trip_part_1\", start_range=0, end_range=25)\n    multi_part_full_vid(video_title=\"trip_part_2\", start_range=26, end_range=50)\n    multi_part_full_vid(video_title=\"trip_part_3\", start_range=51, end_range=71)\n\n# concat_vid_clips(vid_clip_directory='/00000113deccd0eef8')"
  },
  {
    "objectID": "index.html#save-images-from-the-video",
    "href": "index.html#save-images-from-the-video",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Save Images From The Video",
    "text": "Save Images From The Video\nFinally, we play the videos and save an Image every 2500 frames.\n\ndef save_frame_range(\n    video_path: str, \n    start_frame: int, \n    stop_frame: int, \n    step_frame: int,\n    dir_path: str, \n    basename: str, \n    ext='png'):\n\n    cap = cv2.VideoCapture(video_path)\n\n    if not cap.isOpened(): return\n\n    makedirs(dir_path, exist_ok=True)\n    base_path = os.path.join(dir_path, basename)\n\n    digit = len(str(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))\n\n    for n in range(start_frame, stop_frame, step_frame):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n        ret, frame = cap.read()\n        if ret: cv2.imwrite(f'{base_path}_{str(n).zfill(digit)}.{ext}', frame)\n        else: return\n\nsave_frame_range(full_vid_path + '/trip_part_1.mp4', 0, 200000, \n                 2500, images_path, 'part1_video_img_frame')\n\nsave_frame_range(full_vid_path + '/trip_part_2.mp4', 0, 200000, \n                2500, images_path, 'part2_video_img_frame')\n\nsave_frame_range(full_vid_path + '/trip_part_3.mp4', 0, 200000, \n                 2500, images_path, 'part3_video_img_frame')\n\n# save_frame_range(full_vid_path + '/trip_part_4.mp4', 0, 200000, \n#                  2500, images_path, 'part4_video_img_frame')\n\n# image_dir = listdir(images_path)\n# for image in image_dir: print(image)"
  },
  {
    "objectID": "index.html#random-commute",
    "href": "index.html#random-commute",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Random Commute",
    "text": "Random Commute"
  },
  {
    "objectID": "index.html#notable-images-from-part-14",
    "href": "index.html#notable-images-from-part-14",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Notable Images From Part 1/4",
    "text": "Notable Images From Part 1/4\n\n\n\n\n\n\nFrame 1\n\n\n\n\n\n\n\nFrame 2\n\n\n\n\n\n\n\n\n\nFrame 3"
  },
  {
    "objectID": "index.html#plotting-images",
    "href": "index.html#plotting-images",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Plotting Images",
    "text": "Plotting Images\n\ncstat = f'data/route-images/part1_video_img_frame_02500.png'\ncountry_road = f'data/route-images/part3_video_img_frame_10000.png'\ntraffic_light = f'data/route-images/part2_video_img_frame_17500.png'\n\ncstat_image = plt.imread(cstat, format='png')\ncountry_road_image = plt.imread(country_road, format='png')\ntraffic_light_image = plt.imread(traffic_light, format='png')\n\nax0 = isns.imgplot(cstat_image, cmap='seismic', gray=True)\nax2 = isns.imgplot(country_road_image, cmap='seismic', gray=True)\nax3 = isns.imgplot(traffic_light_image, cmap='seismic', gray=True)\nplt.show()"
  },
  {
    "objectID": "index.html#plotting-images---histograms",
    "href": "index.html#plotting-images---histograms",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Plotting Images - Histograms",
    "text": "Plotting Images - Histograms\n\nplt.subplot(2,2,1)\nplt.hist(cstat_image.ravel())\nplt.subplot(2,2,2)\nplt.hist(country_road_image.ravel())\nplt.subplot(2,2,4)\nplt.hist(traffic_light_image.ravel())\nplt.show()"
  },
  {
    "objectID": "index.html#plotting-images---boxplots",
    "href": "index.html#plotting-images---boxplots",
    "title": "Comma AI - Video Processing Driving Data",
    "section": "Plotting Images - Boxplots",
    "text": "Plotting Images - Boxplots\n\nplt.subplot(2,2,1)\nplt.boxplot(cstat_image.ravel())\nplt.subplot(2,2,2)\nplt.boxplot(country_road_image.ravel())\nplt.subplot(2,2,4)\nplt.boxplot(traffic_light_image.ravel())\nplt.show()"
  }
]